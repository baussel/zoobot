{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/walml/repos/zoobot\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up-to-date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from astropy.table import Table  # for NSA\n",
    "from astropy import units as u\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from PIL import Image\n",
    "from scipy.stats import binom\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from shared_astro_utils import astropy_utils, matching_utils\n",
    "from zoobot.estimators import make_predictions, bayesian_estimator_funcs\n",
    "from zoobot.tfrecord import read_tfrecord\n",
    "from zoobot.uncertainty import discrete_coverage\n",
    "from zoobot.estimators import input_utils, losses\n",
    "from zoobot.tfrecord import catalog_to_tfrecord\n",
    "from zoobot.active_learning import metrics, simulated_metrics, acquisition_utils, check_uncertainty, simulation_timeline, default_estimator_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/walml/repos/zoobot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 50\n",
    "end = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the (latest) model under `model_name` folder in `results_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog_loc = 'data/latest_labelled_catalog.csv\n",
    "catalog_loc = 'data/decals/decals_master_catalog.csv'\n",
    "catalog = pd.read_csv(catalog_loc, dtype={'subject_id': str})  # original catalog\n",
    "# catalog = catalog[:5000]  \n",
    "catalog['file_loc'] = catalog['local_png_loc'].apply(lambda x: '/media/walml/beta/decals/png_native' + x[32:])\n",
    "\n",
    "model_name = 'latest_offline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False\n",
      "WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/walml/beta/decals/multilabel_master_256/train/s256_shard_50.tfrecord']\n",
      "loading filenames: <TensorSliceDataset shapes: (), types: tf.string>\n",
      "loading filenames: <TensorSliceDataset shapes: (), types: tf.string>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['J120546.54+055750.8',\n",
       " 'J134127.12+105353.5',\n",
       " 'J124108.42+135738.7',\n",
       " 'J103232.48+143246.7',\n",
       " 'J212033.56+105801.3']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Figures will be saved to here\n",
    "\n",
    "analysis_dir = 'analysis/multiquestion'\n",
    "save_dir = f'{analysis_dir}/{model_name}'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "results_dir = 'results'\n",
    "\n",
    "label_cols = [\n",
    "    'smooth-or-featured_smooth',\n",
    "    'smooth-or-featured_featured-or-disk',\n",
    "    'has-spiral-arms_yes',\n",
    "    'has-spiral-arms_no',\n",
    "    'spiral-winding_tight',\n",
    "    'spiral-winding_medium',\n",
    "    'spiral-winding_loose',\n",
    "    'bar_strong',\n",
    "    'bar_weak',\n",
    "    'bar_no',\n",
    "    'bulge-size_dominant',\n",
    "    'bulge-size_large',\n",
    "    'bulge-size_moderate',\n",
    "    'bulge-size_small',\n",
    "    'bulge-size_none'\n",
    "]\n",
    "\n",
    "questions = [\n",
    "    'smooth-or-featured',\n",
    "    'has-spiral-arms',\n",
    "    'spiral-winding',\n",
    "    'bar',\n",
    "    'bulge-size'\n",
    "]\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "initial_size = 256\n",
    "final_size = 64\n",
    "channels = 3\n",
    "\n",
    "n_samples = 5\n",
    "\n",
    "# if loading single test tfrecord\n",
    "# tfrecord_locs = [f'data/decals/shards/multilabel_{img_size}/eval/s{initial_size}_shard_0.tfrecord']\n",
    "# tfrecord_locs = ['data/decals/shards/multilabel_master_256/train/s256_shard_0.tfrecord']\n",
    "tfrecord_locs = glob.glob(f'/media/walml/beta/decals/multilabel_master_{initial_size}/train/*.tfrecord')[start:end]\n",
    "\n",
    "# tfrecord_locs = ['data/decals/shards/multilabel_all_temp/train/s128_shard_0.tfrecord']\n",
    "print(tfrecord_locs)\n",
    "eval_config = default_estimator_params.get_eval_config(tfrecord_locs, label_cols, batch_size, initial_size, final_size, channels)\n",
    "dataset = input_utils.get_input(config=eval_config)\n",
    "\n",
    "feature_spec = input_utils.get_feature_spec({'id_str': 'string'})\n",
    "id_str_dataset = input_utils.get_dataset(tfrecord_locs, feature_spec, batch_size=1, shuffle=False, repeat=False)\n",
    "id_strs = [str(d['id_str'].numpy().squeeze())[2:-1] for d in id_str_dataset]\n",
    "id_strs[:5]\n",
    "\n",
    "# n = 0\n",
    "# for batch in id_str_dataset:\n",
    "#     for id_str in batch:\n",
    "#         n+=1\n",
    "# print(n)\n",
    "\n",
    "# counter = Counter()\n",
    "# n = 0\n",
    "# for g_batch, y_batch in dataset:\n",
    "# #     for g in g_batch:\n",
    "# #         counter[g.numpy().sum()] += 1\n",
    "#         n+=tf.shape(g_batch)[0]\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2415"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if loading png\n",
    "\n",
    "# print(catalog['file_loc'])\n",
    "# assert all([os.path.isfile(x) for x in catalog['file_loc']])\n",
    "# filenames = tf.constant(list(catalog['file_loc']), dtype=tf.string)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "\n",
    "# def parse_image(im):\n",
    "#     im = tf.image.decode_png(im, channels=channels)\n",
    "#     im = tf.image.convert_image_dtype(im, tf.float32)\n",
    "#     im = tf.image.resize(im, [initial_size, initial_size])\n",
    "#     return im\n",
    "\n",
    "\n",
    "# # for im in dataset.take(1):\n",
    "# #     print(im)\n",
    "\n",
    "# # assert False\n",
    "\n",
    "# dataset = dataset.map(tf.io.read_file)\n",
    "# dataset = dataset.map(parse_image)\n",
    "\n",
    "# config = default_estimator_params.get_eval_config(['do not use'], label_cols, batch_size, initial_size, final_size, channels)\n",
    "\n",
    "# dataset = dataset.batch(batch_size)\n",
    "\n",
    "# # for batch in dataset.take(1):\n",
    "# #     print(tf.shape(batch))\n",
    "# # #     plt.imshow(batch[0])\n",
    "\n",
    "\n",
    "# # dataset = dataset.map(lambda x: check_shape(x))\n",
    "\n",
    "# dataset = dataset.map(lambda x: input_utils.preprocess_images(x, config))\n",
    "\n",
    "\n",
    "# # for batch in dataset.take(1):\n",
    "# #     print(tf.shape(batch))\n",
    "# #     plt.imshow(batch[0].numpy().squeeze())\n",
    "\n",
    "\n",
    "# id_strs = catalog['iauname']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{smooth-or-featured, indices 0 to 1, asked after None: (0, 1), has-spiral-arms, indices 2 to 3, asked after <zoobot.estimators.losses.Answer object at 0x7f4fb01f5e10>: (2, 3), spiral-winding, indices 4 to 6, asked after <zoobot.estimators.losses.Answer object at 0x7f4fa5b8efd0>: (4, 6), bar, indices 7 to 9, asked after <zoobot.estimators.losses.Answer object at 0x7f4fb01f5e10>: (7, 9), bulge-size, indices 10 to 14, asked after <zoobot.estimators.losses.Answer object at 0x7f4fb01f5e10>: (10, 14)}\n",
      "Name: smooth-or-featured, start 0, end 1\n",
      "Name: has-spiral-arms, start 2, end 3\n",
      "Name: spiral-winding, start 4, end 6\n",
      "Name: bar, start 7, end 9\n",
      "Name: bulge-size, start 10, end 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4fb0e7b9d0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = default_estimator_params.get_model(label_cols, questions, final_size)\n",
    "\n",
    "checkpoint_dir = f'{results_dir}/{model_name}/results/models'\n",
    "model.load_weights(checkpoint_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit predictions = model.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 64, 64, 1), (None, 15)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(dataset).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (2, 3), (4, 6), (7, 9), (10, 14)]\n",
      "0 1\n",
      "2 3\n",
      "4 6\n",
      "7 9\n",
      "10 14\n"
     ]
    }
   ],
   "source": [
    "predictions = np.stack([model.predict(dataset) for n in range(n_samples)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2415, 15, 5)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_x, batch_y in dataset:\n",
    "#     print(batch_y.numpy())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = np.concatenate([batch_y for (_, batch_y) in test_dataset], axis=0)\n",
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = catalog[label_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(predictions[:, 0], alpha=0.5, label='Predictions', density=True)\n",
    "# ax.hist(labels[:, 0] / labels[:, :2].sum(axis=1), alpha=0.5, label='Labels', density=True)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predictions[:, 0].min(), labels[:, 0].min())\n",
    "# print(predictions[:, 0].max(), labels[:, 0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{smooth-or-featured, indices 0 to 1, asked after None: (0, 1), has-spiral-arms, indices 2 to 3, asked after <zoobot.estimators.losses.Answer object at 0x7f4fc49d7ed0>: (2, 3), spiral-winding, indices 4 to 6, asked after <zoobot.estimators.losses.Answer object at 0x7f4fc49d7e50>: (4, 6), bar, indices 7 to 9, asked after <zoobot.estimators.losses.Answer object at 0x7f4fc49d7ed0>: (7, 9), bulge-size, indices 10 to 14, asked after <zoobot.estimators.losses.Answer object at 0x7f4fc49d7ed0>: (10, 14)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[smooth-or-featured, indices 0 to 1, asked after None,\n",
       " has-spiral-arms, indices 2 to 3, asked after <zoobot.estimators.losses.Answer object at 0x7f4fc49d7ed0>,\n",
       " spiral-winding, indices 4 to 6, asked after <zoobot.estimators.losses.Answer object at 0x7f4fc49d7e50>,\n",
       " bar, indices 7 to 9, asked after <zoobot.estimators.losses.Answer object at 0x7f4fc49d7ed0>,\n",
       " bulge-size, indices 10 to 14, asked after <zoobot.estimators.losses.Answer object at 0x7f4fc49d7ed0>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = losses.Schema(label_cols, questions)\n",
    "schema.questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquisitions = acquisition_utils.mutual_info_acquisition_func_multiq(predictions, schema, retirement=40)\n",
    "# acquisitions.shape\n",
    "# acquisitions\n",
    "\n",
    "# single_q_acquisitions = np.array(acquisition_utils.mutual_info_acquisition_func(predictions[:, 0], expected_votes=40))\n",
    "# single_q_acquisitions[:5], acquisitions[0, :5], acquisitions[1, :5]  # smooth mutual acq should be identical, for both answers by symmmetry\n",
    "# acquisitions[2, :5], acquisitions[3, :5]  # has-spiral-arms also by symmetry\n",
    "# acquisitions[4, :5], acquisitions[5, :5], acquisitions[6, :5]  # but for spiral winding there are 3 answers so *not* identical\n",
    "# predictions.shape, acquisitions.shape, len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2415, 15, 5), 2415)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape, len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_row(prediction, id_str):\n",
    "    row = {\n",
    "        'id_str': id_str\n",
    "    }\n",
    "    for n, col in enumerate(label_cols):\n",
    "        answer = label_cols[n]\n",
    "        row[answer + '_prediction'] = prediction[n]\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "        row[answer + '_prediction_mean'] = float(prediction[n].mean())\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row['total_acquisition'] = acquisition.sum()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_to_row(prediction, acquisition, id_str):\n",
    "    row = {\n",
    "        'id_str': id_str\n",
    "    }\n",
    "    for n, col in enumerate(label_cols):\n",
    "        answer = label_cols[n]\n",
    "        row[answer + '_prediction'] = prediction[n]\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "        row[answer + '_prediction_mean'] = float(prediction[n].mean())\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row['total_acquisition'] = acquisition.sum()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [prediction_to_row(predictions[n], id_strs[n]) for n in range(len(predictions))]\n",
    "# data = [all_to_row(predictions[n], acquisitions[n], id_strs[n]) for n in range(len(predictions))]\n",
    "predictions_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2415"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>smooth-or-featured_smooth_prediction</th>\n",
       "      <th>smooth-or-featured_smooth_prediction_mean</th>\n",
       "      <th>smooth-or-featured_featured-or-disk_prediction</th>\n",
       "      <th>smooth-or-featured_featured-or-disk_prediction_mean</th>\n",
       "      <th>has-spiral-arms_yes_prediction</th>\n",
       "      <th>has-spiral-arms_yes_prediction_mean</th>\n",
       "      <th>has-spiral-arms_no_prediction</th>\n",
       "      <th>has-spiral-arms_no_prediction_mean</th>\n",
       "      <th>spiral-winding_tight_prediction</th>\n",
       "      <th>...</th>\n",
       "      <th>bulge-size_dominant_prediction</th>\n",
       "      <th>bulge-size_dominant_prediction_mean</th>\n",
       "      <th>bulge-size_large_prediction</th>\n",
       "      <th>bulge-size_large_prediction_mean</th>\n",
       "      <th>bulge-size_moderate_prediction</th>\n",
       "      <th>bulge-size_moderate_prediction_mean</th>\n",
       "      <th>bulge-size_small_prediction</th>\n",
       "      <th>bulge-size_small_prediction_mean</th>\n",
       "      <th>bulge-size_none_prediction</th>\n",
       "      <th>bulge-size_none_prediction_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J120546.54+055750.8</td>\n",
       "      <td>[0.30420297, 0.29689792, 0.1815976, 0.27818456...</td>\n",
       "      <td>0.252087</td>\n",
       "      <td>[0.6957971, 0.7031021, 0.81840235, 0.7218154, ...</td>\n",
       "      <td>0.747913</td>\n",
       "      <td>[0.77654797, 0.68017673, 0.9010634, 0.79541725...</td>\n",
       "      <td>0.805829</td>\n",
       "      <td>[0.22345208, 0.31982327, 0.09893663, 0.2045827...</td>\n",
       "      <td>0.194171</td>\n",
       "      <td>[0.36976084, 0.5811233, 0.54553777, 0.5828835,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0246401, 0.02125156, 0.01801422, 0.02128763...</td>\n",
       "      <td>0.020114</td>\n",
       "      <td>[0.06994944, 0.04650045, 0.053316157, 0.038661...</td>\n",
       "      <td>0.049567</td>\n",
       "      <td>[0.5141608, 0.43578383, 0.4751809, 0.31585756,...</td>\n",
       "      <td>0.435906</td>\n",
       "      <td>[0.36725083, 0.46015358, 0.4309142, 0.552231, ...</td>\n",
       "      <td>0.457002</td>\n",
       "      <td>[0.023998888, 0.036310542, 0.022574492, 0.0719...</td>\n",
       "      <td>0.037411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J134127.12+105353.5</td>\n",
       "      <td>[0.66698474, 0.6663146, 0.662525, 0.7146262, 0...</td>\n",
       "      <td>0.690463</td>\n",
       "      <td>[0.33301523, 0.33368537, 0.33747497, 0.2853738...</td>\n",
       "      <td>0.309537</td>\n",
       "      <td>[0.23337178, 0.30273125, 0.49857944, 0.2058643...</td>\n",
       "      <td>0.282494</td>\n",
       "      <td>[0.76662827, 0.6972688, 0.50142056, 0.79413563...</td>\n",
       "      <td>0.717506</td>\n",
       "      <td>[0.44853082, 0.250708, 0.31300673, 0.3163705, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.07231821, 0.0875522, 0.0803811, 0.049855016...</td>\n",
       "      <td>0.072807</td>\n",
       "      <td>[0.22716962, 0.28933305, 0.2419108, 0.15618472...</td>\n",
       "      <td>0.219773</td>\n",
       "      <td>[0.5412547, 0.47177008, 0.51008976, 0.55140704...</td>\n",
       "      <td>0.528380</td>\n",
       "      <td>[0.14002505, 0.121737115, 0.14817934, 0.219411...</td>\n",
       "      <td>0.156028</td>\n",
       "      <td>[0.019232363, 0.029607613, 0.019438962, 0.0231...</td>\n",
       "      <td>0.023013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J124108.42+135738.7</td>\n",
       "      <td>[0.5939548, 0.5553277, 0.63378006, 0.59075475,...</td>\n",
       "      <td>0.595311</td>\n",
       "      <td>[0.40604523, 0.4446723, 0.36621988, 0.40924525...</td>\n",
       "      <td>0.404689</td>\n",
       "      <td>[0.31524974, 0.50869465, 0.34540093, 0.4710049...</td>\n",
       "      <td>0.405067</td>\n",
       "      <td>[0.6847502, 0.4913053, 0.6545991, 0.528995, 0....</td>\n",
       "      <td>0.594933</td>\n",
       "      <td>[0.3221565, 0.32892954, 0.34041446, 0.26781067...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.060038064, 0.044161692, 0.06280769, 0.06437...</td>\n",
       "      <td>0.057201</td>\n",
       "      <td>[0.20401071, 0.16899005, 0.19661307, 0.2424580...</td>\n",
       "      <td>0.209927</td>\n",
       "      <td>[0.5576686, 0.5837672, 0.56842136, 0.5288443, ...</td>\n",
       "      <td>0.544825</td>\n",
       "      <td>[0.15632583, 0.18357164, 0.1519133, 0.14060122...</td>\n",
       "      <td>0.162504</td>\n",
       "      <td>[0.021956755, 0.019509498, 0.020244569, 0.0237...</td>\n",
       "      <td>0.025542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J103232.48+143246.7</td>\n",
       "      <td>[0.24313717, 0.296936, 0.2039256, 0.21983513, ...</td>\n",
       "      <td>0.217450</td>\n",
       "      <td>[0.7568629, 0.70306396, 0.79607445, 0.78016484...</td>\n",
       "      <td>0.782551</td>\n",
       "      <td>[0.91874164, 0.8905016, 0.91629034, 0.94856566...</td>\n",
       "      <td>0.928969</td>\n",
       "      <td>[0.0812584, 0.10949836, 0.08370964, 0.05143435...</td>\n",
       "      <td>0.071031</td>\n",
       "      <td>[0.48085463, 0.47088748, 0.47635913, 0.4744492...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.025323467, 0.02414925, 0.029758457, 0.01648...</td>\n",
       "      <td>0.022470</td>\n",
       "      <td>[0.056805905, 0.09140686, 0.063217394, 0.04846...</td>\n",
       "      <td>0.057665</td>\n",
       "      <td>[0.37605965, 0.3769583, 0.34806174, 0.39062214...</td>\n",
       "      <td>0.357599</td>\n",
       "      <td>[0.5147198, 0.43075505, 0.5246157, 0.5111978, ...</td>\n",
       "      <td>0.523047</td>\n",
       "      <td>[0.027091227, 0.07673053, 0.03434673, 0.033224...</td>\n",
       "      <td>0.039219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J212033.56+105801.3</td>\n",
       "      <td>[0.6517667, 0.73542684, 0.7160145, 0.7482792, ...</td>\n",
       "      <td>0.708516</td>\n",
       "      <td>[0.3482333, 0.26457322, 0.2839855, 0.25172082,...</td>\n",
       "      <td>0.291484</td>\n",
       "      <td>[0.08934232, 0.20825186, 0.117199324, 0.059358...</td>\n",
       "      <td>0.160870</td>\n",
       "      <td>[0.9106577, 0.79174817, 0.8828007, 0.94064116,...</td>\n",
       "      <td>0.839130</td>\n",
       "      <td>[0.24652085, 0.16471621, 0.12415182, 0.1637303...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.118599854, 0.08799145, 0.14941905, 0.127707...</td>\n",
       "      <td>0.117834</td>\n",
       "      <td>[0.4488062, 0.35998735, 0.30993697, 0.36788717...</td>\n",
       "      <td>0.372014</td>\n",
       "      <td>[0.38391578, 0.49395758, 0.49997556, 0.4455365...</td>\n",
       "      <td>0.458517</td>\n",
       "      <td>[0.036783103, 0.04825744, 0.03501271, 0.049017...</td>\n",
       "      <td>0.042630</td>\n",
       "      <td>[0.011895055, 0.009806191, 0.0056557204, 0.009...</td>\n",
       "      <td>0.009005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str               smooth-or-featured_smooth_prediction  \\\n",
       "0  J120546.54+055750.8  [0.30420297, 0.29689792, 0.1815976, 0.27818456...   \n",
       "1  J134127.12+105353.5  [0.66698474, 0.6663146, 0.662525, 0.7146262, 0...   \n",
       "2  J124108.42+135738.7  [0.5939548, 0.5553277, 0.63378006, 0.59075475,...   \n",
       "3  J103232.48+143246.7  [0.24313717, 0.296936, 0.2039256, 0.21983513, ...   \n",
       "4  J212033.56+105801.3  [0.6517667, 0.73542684, 0.7160145, 0.7482792, ...   \n",
       "\n",
       "   smooth-or-featured_smooth_prediction_mean  \\\n",
       "0                                   0.252087   \n",
       "1                                   0.690463   \n",
       "2                                   0.595311   \n",
       "3                                   0.217450   \n",
       "4                                   0.708516   \n",
       "\n",
       "      smooth-or-featured_featured-or-disk_prediction  \\\n",
       "0  [0.6957971, 0.7031021, 0.81840235, 0.7218154, ...   \n",
       "1  [0.33301523, 0.33368537, 0.33747497, 0.2853738...   \n",
       "2  [0.40604523, 0.4446723, 0.36621988, 0.40924525...   \n",
       "3  [0.7568629, 0.70306396, 0.79607445, 0.78016484...   \n",
       "4  [0.3482333, 0.26457322, 0.2839855, 0.25172082,...   \n",
       "\n",
       "   smooth-or-featured_featured-or-disk_prediction_mean  \\\n",
       "0                                           0.747913     \n",
       "1                                           0.309537     \n",
       "2                                           0.404689     \n",
       "3                                           0.782551     \n",
       "4                                           0.291484     \n",
       "\n",
       "                      has-spiral-arms_yes_prediction  \\\n",
       "0  [0.77654797, 0.68017673, 0.9010634, 0.79541725...   \n",
       "1  [0.23337178, 0.30273125, 0.49857944, 0.2058643...   \n",
       "2  [0.31524974, 0.50869465, 0.34540093, 0.4710049...   \n",
       "3  [0.91874164, 0.8905016, 0.91629034, 0.94856566...   \n",
       "4  [0.08934232, 0.20825186, 0.117199324, 0.059358...   \n",
       "\n",
       "   has-spiral-arms_yes_prediction_mean  \\\n",
       "0                             0.805829   \n",
       "1                             0.282494   \n",
       "2                             0.405067   \n",
       "3                             0.928969   \n",
       "4                             0.160870   \n",
       "\n",
       "                       has-spiral-arms_no_prediction  \\\n",
       "0  [0.22345208, 0.31982327, 0.09893663, 0.2045827...   \n",
       "1  [0.76662827, 0.6972688, 0.50142056, 0.79413563...   \n",
       "2  [0.6847502, 0.4913053, 0.6545991, 0.528995, 0....   \n",
       "3  [0.0812584, 0.10949836, 0.08370964, 0.05143435...   \n",
       "4  [0.9106577, 0.79174817, 0.8828007, 0.94064116,...   \n",
       "\n",
       "   has-spiral-arms_no_prediction_mean  \\\n",
       "0                            0.194171   \n",
       "1                            0.717506   \n",
       "2                            0.594933   \n",
       "3                            0.071031   \n",
       "4                            0.839130   \n",
       "\n",
       "                     spiral-winding_tight_prediction  ...  \\\n",
       "0  [0.36976084, 0.5811233, 0.54553777, 0.5828835,...  ...   \n",
       "1  [0.44853082, 0.250708, 0.31300673, 0.3163705, ...  ...   \n",
       "2  [0.3221565, 0.32892954, 0.34041446, 0.26781067...  ...   \n",
       "3  [0.48085463, 0.47088748, 0.47635913, 0.4744492...  ...   \n",
       "4  [0.24652085, 0.16471621, 0.12415182, 0.1637303...  ...   \n",
       "\n",
       "                      bulge-size_dominant_prediction  \\\n",
       "0  [0.0246401, 0.02125156, 0.01801422, 0.02128763...   \n",
       "1  [0.07231821, 0.0875522, 0.0803811, 0.049855016...   \n",
       "2  [0.060038064, 0.044161692, 0.06280769, 0.06437...   \n",
       "3  [0.025323467, 0.02414925, 0.029758457, 0.01648...   \n",
       "4  [0.118599854, 0.08799145, 0.14941905, 0.127707...   \n",
       "\n",
       "  bulge-size_dominant_prediction_mean  \\\n",
       "0                            0.020114   \n",
       "1                            0.072807   \n",
       "2                            0.057201   \n",
       "3                            0.022470   \n",
       "4                            0.117834   \n",
       "\n",
       "                         bulge-size_large_prediction  \\\n",
       "0  [0.06994944, 0.04650045, 0.053316157, 0.038661...   \n",
       "1  [0.22716962, 0.28933305, 0.2419108, 0.15618472...   \n",
       "2  [0.20401071, 0.16899005, 0.19661307, 0.2424580...   \n",
       "3  [0.056805905, 0.09140686, 0.063217394, 0.04846...   \n",
       "4  [0.4488062, 0.35998735, 0.30993697, 0.36788717...   \n",
       "\n",
       "  bulge-size_large_prediction_mean  \\\n",
       "0                         0.049567   \n",
       "1                         0.219773   \n",
       "2                         0.209927   \n",
       "3                         0.057665   \n",
       "4                         0.372014   \n",
       "\n",
       "                      bulge-size_moderate_prediction  \\\n",
       "0  [0.5141608, 0.43578383, 0.4751809, 0.31585756,...   \n",
       "1  [0.5412547, 0.47177008, 0.51008976, 0.55140704...   \n",
       "2  [0.5576686, 0.5837672, 0.56842136, 0.5288443, ...   \n",
       "3  [0.37605965, 0.3769583, 0.34806174, 0.39062214...   \n",
       "4  [0.38391578, 0.49395758, 0.49997556, 0.4455365...   \n",
       "\n",
       "  bulge-size_moderate_prediction_mean  \\\n",
       "0                            0.435906   \n",
       "1                            0.528380   \n",
       "2                            0.544825   \n",
       "3                            0.357599   \n",
       "4                            0.458517   \n",
       "\n",
       "                         bulge-size_small_prediction  \\\n",
       "0  [0.36725083, 0.46015358, 0.4309142, 0.552231, ...   \n",
       "1  [0.14002505, 0.121737115, 0.14817934, 0.219411...   \n",
       "2  [0.15632583, 0.18357164, 0.1519133, 0.14060122...   \n",
       "3  [0.5147198, 0.43075505, 0.5246157, 0.5111978, ...   \n",
       "4  [0.036783103, 0.04825744, 0.03501271, 0.049017...   \n",
       "\n",
       "  bulge-size_small_prediction_mean  \\\n",
       "0                         0.457002   \n",
       "1                         0.156028   \n",
       "2                         0.162504   \n",
       "3                         0.523047   \n",
       "4                         0.042630   \n",
       "\n",
       "                          bulge-size_none_prediction  \\\n",
       "0  [0.023998888, 0.036310542, 0.022574492, 0.0719...   \n",
       "1  [0.019232363, 0.029607613, 0.019438962, 0.0231...   \n",
       "2  [0.021956755, 0.019509498, 0.020244569, 0.0237...   \n",
       "3  [0.027091227, 0.07673053, 0.03434673, 0.033224...   \n",
       "4  [0.011895055, 0.009806191, 0.0056557204, 0.009...   \n",
       "\n",
       "  bulge-size_none_prediction_mean  \n",
       "0                        0.037411  \n",
       "1                        0.023013  \n",
       "2                        0.025542  \n",
       "3                        0.039219  \n",
       "4                        0.009005  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['iauname'] = predictions_df['id_str']\n",
    "df = pd.merge(catalog, predictions_df, how='inner', on='iauname')\n",
    "len(df)\n",
    "assert len(df) == len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'iauname', 'nsa_id', 'ra_subject', 'dec_subject',\n",
       "       'petrotheta', 'petroth50', 'petroth90', 'redshift',\n",
       "       'local_fits_loc', 'local_png_loc', 'fits_ready', 'fits_filled',\n",
       "       'png_ready', 'best_match', 'sky_separation', 'nsa_version', 'mag',\n",
       "       'ra', 'dec', 'file_loc', 'subject_id', 'bar_no', 'bar_strong',\n",
       "       'bar_weak', 'bulge-size_dominant', 'bulge-size_large',\n",
       "       'bulge-size_moderate', 'bulge-size_none', 'bulge-size_small',\n",
       "       'disk-edge-on_no', 'disk-edge-on_yes', 'edge-on-bulge_boxy',\n",
       "       'edge-on-bulge_none', 'edge-on-bulge_rounded',\n",
       "       'has-spiral-arms_no', 'has-spiral-arms_yes',\n",
       "       'how-rounded_cigar-shaped', 'how-rounded_in-between',\n",
       "       'how-rounded_round', 'merging_both-v1',\n",
       "       'merging_major-disturbance', 'merging_merger',\n",
       "       'merging_minor-disturbance', 'merging_neither-v1', 'merging_none',\n",
       "       'merging_tidal-debris-v1', 'smooth-or-featured_artifact',\n",
       "       'smooth-or-featured_featured-or-disk', 'smooth-or-featured_smooth',\n",
       "       'spiral-arm-count_1', 'spiral-arm-count_2', 'spiral-arm-count_3',\n",
       "       'spiral-arm-count_4', 'spiral-arm-count_cant-tell',\n",
       "       'spiral-arm-count_more-than-4', 'spiral-winding_loose',\n",
       "       'spiral-winding_medium', 'spiral-winding_tight',\n",
       "       'smooth-or-featured_total-votes', 'how-rounded_total-votes',\n",
       "       'disk-edge-on_total-votes', 'edge-on-bulge_total-votes',\n",
       "       'bar_total-votes', 'has-spiral-arms_total-votes',\n",
       "       'spiral-winding_total-votes', 'spiral-arm-count_total-votes',\n",
       "       'bulge-size_total-votes', 'merging_total-votes',\n",
       "       'smooth-or-featured_smooth_fraction',\n",
       "       'smooth-or-featured_featured-or-disk_fraction',\n",
       "       'smooth-or-featured_artifact_fraction',\n",
       "       'how-rounded_round_fraction', 'how-rounded_in-between_fraction',\n",
       "       'how-rounded_cigar-shaped_fraction', 'disk-edge-on_yes_fraction',\n",
       "       'disk-edge-on_no_fraction', 'edge-on-bulge_rounded_fraction',\n",
       "       'edge-on-bulge_boxy_fraction', 'edge-on-bulge_none_fraction',\n",
       "       'bar_strong_fraction', 'bar_weak_fraction', 'bar_no_fraction',\n",
       "       'has-spiral-arms_yes_fraction', 'has-spiral-arms_no_fraction',\n",
       "       'spiral-winding_tight_fraction', 'spiral-winding_medium_fraction',\n",
       "       'spiral-winding_loose_fraction', 'spiral-arm-count_1_fraction',\n",
       "       'spiral-arm-count_2_fraction', 'spiral-arm-count_3_fraction',\n",
       "       'spiral-arm-count_4_fraction',\n",
       "       'spiral-arm-count_more-than-4_fraction',\n",
       "       'spiral-arm-count_cant-tell_fraction', 'bulge-size_none_fraction',\n",
       "       'bulge-size_small_fraction', 'bulge-size_moderate_fraction',\n",
       "       'bulge-size_large_fraction', 'bulge-size_dominant_fraction',\n",
       "       'merging_merger_fraction', 'merging_tidal-debris-v1_fraction',\n",
       "       'merging_both-v1_fraction', 'merging_neither-v1_fraction',\n",
       "       'merging_major-disturbance_fraction',\n",
       "       'merging_minor-disturbance_fraction', 'merging_none_fraction',\n",
       "       'retirement_limit', 'subject_url', 'upload_date', 'uploader',\n",
       "       'id_str', 'smooth-or-featured_smooth_prediction',\n",
       "       'smooth-or-featured_smooth_prediction_mean',\n",
       "       'smooth-or-featured_featured-or-disk_prediction',\n",
       "       'smooth-or-featured_featured-or-disk_prediction_mean',\n",
       "       'has-spiral-arms_yes_prediction',\n",
       "       'has-spiral-arms_yes_prediction_mean',\n",
       "       'has-spiral-arms_no_prediction',\n",
       "       'has-spiral-arms_no_prediction_mean',\n",
       "       'spiral-winding_tight_prediction',\n",
       "       'spiral-winding_tight_prediction_mean',\n",
       "       'spiral-winding_medium_prediction',\n",
       "       'spiral-winding_medium_prediction_mean',\n",
       "       'spiral-winding_loose_prediction',\n",
       "       'spiral-winding_loose_prediction_mean', 'bar_strong_prediction',\n",
       "       'bar_strong_prediction_mean', 'bar_weak_prediction',\n",
       "       'bar_weak_prediction_mean', 'bar_no_prediction',\n",
       "       'bar_no_prediction_mean', 'bulge-size_dominant_prediction',\n",
       "       'bulge-size_dominant_prediction_mean',\n",
       "       'bulge-size_large_prediction', 'bulge-size_large_prediction_mean',\n",
       "       'bulge-size_moderate_prediction',\n",
       "       'bulge-size_moderate_prediction_mean',\n",
       "       'bulge-size_small_prediction', 'bulge-size_small_prediction_mean',\n",
       "       'bulge-size_none_prediction', 'bulge-size_none_prediction_mean'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       https://panoptes-uploads.zooniverse.org/produc...\n",
       "1       https://panoptes-uploads.zooniverse.org/produc...\n",
       "2       https://panoptes-uploads.zooniverse.org/produc...\n",
       "3       https://panoptes-uploads.zooniverse.org/produc...\n",
       "4       https://panoptes-uploads.zooniverse.org/produc...\n",
       "                              ...                        \n",
       "2410                                                  NaN\n",
       "2411                                                  NaN\n",
       "2412                                                  NaN\n",
       "2413                                                  NaN\n",
       "2414                                                  NaN\n",
       "Name: subject_url, Length: 2415, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /media/walml/beta/decals/png_native/dr5/J114/J...\n",
       "1       /media/walml/beta/decals/png_native/dr5/J114/J...\n",
       "2       /media/walml/beta/decals/png_native/dr5/J115/J...\n",
       "3       /media/walml/beta/decals/png_native/dr5/J120/J...\n",
       "4       /media/walml/beta/decals/png_native/dr5/J115/J...\n",
       "                              ...                        \n",
       "2410    /media/walml/beta/decals/png_native/dr5/J104/J...\n",
       "2411    /media/walml/beta/decals/png_native/dr5/J105/J...\n",
       "2412    /media/walml/beta/decals/png_native/dr5/J140/J...\n",
       "2413    /media/walml/beta/decals/png_native/dr5/J142/J...\n",
       "2414    /media/walml/beta/decals/png_native/dr5/J143/J...\n",
       "Name: file_loc, Length: 2415, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['file_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('temp/master_256_predictions_{}_{}.csv'.format(start, end), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from trust_the_model.ipynb\n",
    "def show_galaxies(df, scale=3, nrows=3, ncols=3):\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    plt.figure(figsize=(scale * nrows, scale * ncols * 1.025))\n",
    "    gs1 = gridspec.GridSpec(nrows, ncols)\n",
    "    gs1.update(wspace=0.0, hspace=0.0)\n",
    "    galaxy_n = 0\n",
    "    for row_n in range(nrows):\n",
    "        for col_n in range(ncols):\n",
    "            galaxy = df.iloc[galaxy_n]\n",
    "            image = Image.open(galaxy['file_loc'])\n",
    "            ax = plt.subplot(gs1[row_n, col_n])\n",
    "            ax.imshow(image)\n",
    "#             ax.text(10, 20, 'Smooth = {:.2f}'.format(galaxy['smooth-or-featured_smooth_fraction']), fontsize=12, color='r')\n",
    "#             ax.text(10, 50, r'$\\rho = {:.2f}$, Var ${:.3f}$'.format(galaxy['median_prediction'], 3*galaxy['predictions_var']), fontsize=12, color='r')\n",
    "#             ax.text(10, 80, '$L = {:.2f}$'.format(galaxy['bcnn_likelihood']), fontsize=12, color='r')\n",
    "            ax.axis('off')\n",
    "            galaxy_n += 1\n",
    "#     print('Mean L: {:.2f}'.format(df[:nrows * ncols]['bcnn_likelihood'].mean()))\n",
    "    fig = plt.gcf()\n",
    "#     fig.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_top_n(schema, save_dir):\n",
    "    for question in schema.questions:\n",
    "        for answer in question.answers:\n",
    "            fig = show_galaxies(df.sort_values(answer.text + '_prediction_mean', ascending=False)[:9])\n",
    "            fig.savefig(save_dir + '_' + answer.text + '.png')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'results/temp'\n",
    "save_top_n(schema, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  # moove later analysis elsewhere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 0], labels[:, 0] / labels[:, :2].sum(axis=1))\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 4], labels[:, 4] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 5], labels[:, 5] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 6], labels[:, 6] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check that the right models have been loaded - should be around 40 for smooth, 0-40 for bars\n",
    "# plt.hist(sim_model.total_votes), sim_model.total_votes.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for systematic offset - in general, model seems slightly skewed towards low k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_single_answer_data(df, answer, n=10):\n",
    "    samples = np.stack(df[answer.text + '_prediction'][:n])\n",
    "    labels = df[answer.text][:n].values.astype(int)\n",
    "    total_votes = df[answer.question.text + '_total-votes'][:n].values.astype(int)\n",
    "    return samples, labels, total_votes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_population_stats(samples, labels, total_votes, title):\n",
    "    # sns.set_context('paper')\n",
    "    sns.set(font_scale=1.)\n",
    "    sns.set_style('white')\n",
    "    alpha = 0.5\n",
    "    # matplotlib.rcParams.update({'font.size': 50}\n",
    "    \n",
    "    mean_samples = samples.mean(axis=-1)\n",
    "    expected_k = mean_samples * total_votes\n",
    "\n",
    "    # dummy for bins\n",
    "    fig, (ax0, ax1) = plt.subplots(nrows=2)\n",
    "    _, bins_rho, _ = ax0.hist(labels/ total_votes, bins=25, alpha=alpha, label='Actual')\n",
    "    _, bins_k, _ = ax1.hist(labels, bins=25, alpha=alpha, label='Actual')\n",
    "    plt.close()\n",
    "\n",
    "    # now for real\n",
    "    fig, (ax0, ax1) = plt.subplots(nrows=2)\n",
    "\n",
    "    _, bins, _ = ax0.hist(mean_samples, bins=bins_rho, alpha=alpha, label='Model')\n",
    "    ax0.hist(labels/ total_votes, bins=bins_rho, alpha=alpha, label='Actual')\n",
    "    ax0.set_xlabel(r'Vote Fraction $\\rho$')\n",
    "    ax0.set_ylabel('Galaxies')\n",
    "    ax0.legend()\n",
    "    ax0.set_xlim([0., 1.])\n",
    "\n",
    "    _, bins, _ = ax1.hist(expected_k, bins=bins_k, alpha=alpha, label='Model')\n",
    "    ax1.hist(labels, bins=bins_k, alpha=alpha, label='Actual')\n",
    "    ax1.set_xlabel(r'Positive Responses $k$')\n",
    "    ax1.set_ylabel('Galaxies')\n",
    "    ax1.legend()\n",
    "    ax1.set_xlim([0, 40])\n",
    "\n",
    "    ax0.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "    # fig.savefig(os.path.join(save_dir, 'posterior_over_full_sample.png'))\n",
    "    # fig.savefig(os.path.join(save_dir, 'posterior_over_full_sample.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answer = schema.get_answer('smooth-or-featured_smooth')\n",
    "samples, labels, total_votes = get_single_answer_data(df, answer, n=len(df))\n",
    "_ = show_population_stats(samples, labels, total_votes, answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for answer in schema.answers:\n",
    "    samples, labels, total_votes = get_single_answer_data(df, answer, n=len(df))\n",
    "    fig = show_population_stats(samples, labels, total_votes, answer.text)\n",
    "    fig.savefig(save_dir + '/population_distribution_' + answer.text + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_samples(samples, labels, total_votes):\n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    fig, axes = plt.subplots(nrows=len(labels), figsize=(3, len(labels)*1.5), sharex=True)\n",
    "    make_predictions.plot_samples(samples, labels, total_votes, fig, axes, alpha=0.06)\n",
    "    for ax in axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "    \n",
    "    for n in range(len(labels)):\n",
    "#         axes[n].set_ylabel(r'$p(v|D)$', visible=True)\n",
    "        axes[n].set_ylabel(r'$p(v|w)$', visible=True)\n",
    "        axes[n].yaxis.set_visible(True)\n",
    "    \n",
    "    axes[-1].set_xlabel('Volunteer Votes')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = 'smooth-or-featured'\n",
    "answer = 'smooth'\n",
    "n = 5\n",
    "samples, labels, total_votes = get_single_answer_data(df, question, answer)\n",
    "_ = custom_samples(samples, labels, total_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = 'has-spiral-arms'\n",
    "answer = 'yes'\n",
    "n = 5\n",
    "samples, labels, total_votes = get_single_answer_data(df, question, answer)\n",
    "_ = custom_samples(samples, labels, total_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def galaxy_posterior_grid(df, schema):\n",
    "    \n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    \n",
    "    scale = 1.5\n",
    "    \n",
    "    im_width = 2\n",
    "    posterior_width = 3\n",
    "    height = im_width\n",
    "    \n",
    "    n_galaxies = len(df)\n",
    "    n_posteriors = len(schema.answers)\n",
    "    \n",
    "    fig = plt.figure(figsize=(scale * (im_width + posterior_width*n_posteriors), (scale * n_galaxies * height)))  # width, height format\n",
    "    gs = gridspec.GridSpec(len(df) * height, im_width + posterior_width * len(schema.answers))  # y, x format\n",
    "    image_axes = []\n",
    "    posterior_axes = []  # (galaxy i.e. row, answer) shape\n",
    "    \n",
    "    # create the grid\n",
    "    for galaxy_n in range(len(df)):\n",
    "        y_slice = slice(galaxy_n*height, (galaxy_n+1)*height)\n",
    "        image_axes.append(plt.subplot(gs[y_slice, :im_width]))\n",
    "        \n",
    "        temp_galaxy_axes = []\n",
    "        for answer_n, answer in enumerate(schema.answers):\n",
    "            x_slice = slice(im_width+answer_n*posterior_width, im_width+(answer_n+1)*posterior_width)\n",
    "            temp_galaxy_axes.append(plt.subplot(gs[y_slice, x_slice]))\n",
    "        posterior_axes.append(temp_galaxy_axes)\n",
    "        \n",
    "    \n",
    "    # fill the images\n",
    "    for ax_n, ax in enumerate(image_axes):\n",
    "        plot_galaxy(df['file_loc'][ax_n], ax)\n",
    "    \n",
    "    # fill the posteriors\n",
    "    for answer_n, answer in enumerate(schema.answers):\n",
    "        samples, labels, total_votes = get_single_answer_data(df, answer)\n",
    "        galaxy_axes = [axes[answer_n] for axes in posterior_axes]\n",
    "        make_predictions.plot_samples(samples, labels, total_votes, fig, galaxy_axes, alpha=0.06)\n",
    "    \n",
    "    # fix x limits for comparison\n",
    "    for row_n, axes in enumerate(posterior_axes):\n",
    "        for answer_n, ax in enumerate(axes):\n",
    "            ax.set_xlim([0, 50])\n",
    "            if row_n == 0:\n",
    "                ax.set_title(schema.answers[answer_n].text)\n",
    "        \n",
    "#     for n in range(len(labels)):\n",
    "#         multiple_axes[n].set_ylabel(r'$p(k|N, D)$', visible=True)\n",
    "#         multiple_axes[n].yaxis.set_visible(True)\n",
    "#         single_axes[n].set_ylabel(r'$p(k|N, w)$', visible=True)\n",
    "#         single_axes[n].yaxis.set_visible(True)\n",
    "#         single_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "#         multiple_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "#         if n < len(labels) - 1:\n",
    "#             single_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "#             multiple_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "# #     if QUESTION == 'bars':\n",
    "# #         question = 'Bar'\n",
    "# #     else:\n",
    "# #         question = 'Smooth'\n",
    "# #     single_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "# #     multiple_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "#     fig.tight_layout()\n",
    "\n",
    "    \n",
    "#     multiple_axes[0].legend(\n",
    "#         loc='lower center', \n",
    "#         bbox_to_anchor=(0.5, 1.1),\n",
    "#         ncol=1, \n",
    "#         fancybox=True, \n",
    "#         shadow=False\n",
    "#     )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = galaxy_posterior_grid(df[:5], schema)\n",
    "fig.savefig(save_dir + '/grid.pdf')\n",
    "fig.savefig(save_dir + '/grid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_samples_with_galaxies(samples, labels, total_votes, png_locs):\n",
    "    \n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    \n",
    "    im_width = 2\n",
    "    single_width = 3\n",
    "    multiple_width = 3\n",
    "    height = im_width\n",
    "    \n",
    "    fig = plt.figure(figsize=(0.8 * len(labels) * height * 2., 0.8 * (im_width + single_width + multiple_width) * 1.75))\n",
    "    gs = gridspec.GridSpec(len(labels) * height, im_width + single_width + multiple_width)  # y, x format\n",
    "    image_axes = []\n",
    "    single_axes = []\n",
    "    multiple_axes = []\n",
    "    for galaxy_n in range(len(labels)):\n",
    "        x_slice = slice(galaxy_n*height, (galaxy_n+1)*height)\n",
    "        image_axes.append(plt.subplot(gs[x_slice, :im_width]))\n",
    "        single_axes.append(plt.subplot(gs[x_slice, im_width:im_width+single_width]))\n",
    "        multiple_axes.append(plt.subplot(gs[x_slice, im_width+single_width:]))\n",
    "    \n",
    "\n",
    "#     fig, axes = plt.subplots(nrows=len(labels), figsize=(3, len(labels)*1.5), sharex=True)\n",
    "    make_predictions.plot_samples(samples[:, :1], labels, total_votes, fig, single_axes, alpha=0.06)\n",
    "    for ax in single_axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "\n",
    "    make_predictions.plot_samples(samples, labels, total_votes, fig, multiple_axes, alpha=0.06)\n",
    "    for ax in multiple_axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "        \n",
    "        \n",
    "    for ax_n, ax in enumerate(image_axes):\n",
    "        plot_galaxy(png_locs[ax_n], ax)\n",
    "        \n",
    "    \n",
    "    for n in range(len(labels)):\n",
    "        multiple_axes[n].set_ylabel(r'$p(k|N, D)$', visible=True)\n",
    "        multiple_axes[n].yaxis.set_visible(True)\n",
    "        single_axes[n].set_ylabel(r'$p(k|N, w)$', visible=True)\n",
    "        single_axes[n].yaxis.set_visible(True)\n",
    "        single_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "        multiple_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "        if n < len(labels) - 1:\n",
    "            single_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "            multiple_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "#     if QUESTION == 'bars':\n",
    "#         question = 'Bar'\n",
    "#     else:\n",
    "#         question = 'Smooth'\n",
    "#     single_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "#     multiple_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    single_axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "    \n",
    "    multiple_axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_galaxy(image_loc, ax, n_examples=10, crop=0):\n",
    "    im_size = 424\n",
    "    im = Image.open(image_loc)\n",
    "#     if QUESTION == 'bars':\n",
    "#         crop = 120\n",
    "#     else:\n",
    "    crop = 35\n",
    "    cropped_im = im.crop((crop, crop, 424 - crop, 424 - crop))\n",
    "    ax.imshow(cropped_im)\n",
    "    ax.grid(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'has-spiral-arms'\n",
    "answer = 'yes'\n",
    "n = 5\n",
    "samples, labels, total_votes = get_single_answer_data(question, answer)\n",
    "png_locs = df['file_loc'][:n]\n",
    "\n",
    "# catalog = sim_model.catalog[selected_slice]\n",
    "\n",
    "_ = custom_samples_with_galaxies(samples, labels, total_votes, png_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 10, figsize=(20, 12))\n",
    "# for ax_n, ax in enumerate(axes):\n",
    "#     plot_galaxy(sim_model.catalog.iloc[ax_n]['png_loc'], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = slice(80, 73, -1)  # smooth\n",
    "\n",
    "# selected = slice(0, 7)\n",
    "\n",
    "if QUESTION == 'bars':\n",
    "    selected = slice(0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(sim_model.model.samples)[selected, :]\n",
    "# np.array(sim_model.labels)[selected]\n",
    "# sim_model.catalog['smooth-or-featured_total-votes'][selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = custom_samples_with_galaxies(sim_model, selected)\n",
    "# fig.savefig(os.path.join(save_dir, 'mc_model_{}.png'.format(len(np.array(sim_model.labels)[selected]))))\n",
    "# fig.savefig(os.path.join(save_dir, 'mc_model_{}.pdf'.format(len(np.array(sim_model.labels)[selected]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure to switch label in custom_samples before running this\n",
    "# fig = custom_samples(np.array(single_sim_model.model.samples)[selected, :1], np.array(single_sim_model.labels)[selected], total_votes=single_sim_model.total_votes)\n",
    "# fig.savefig(os.path.join(save_dir, 'single_model_{}.png'.format(len(np.array(sim_model.labels)[selected]))))\n",
    "# fig.savefig(os.path.join(save_dir, 'single_model_{}.eps'.format(len(np.array(sim_model.labels)[selected]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ungrouped_coverage_df = discrete_coverage.evaluate_discrete_coverage(\n",
    "    sim_model.labels, \n",
    "    sim_model.bin_probs)\n",
    "coverage_df = ungrouped_coverage_df.groupby('max_state_error').agg({'prediction': 'sum', 'observed': 'sum'}).reset_index()\n",
    "\n",
    "ungrouped_single_coverage_df = discrete_coverage.evaluate_discrete_coverage(\n",
    "    single_sim_model.labels, \n",
    "    single_sim_model.bin_probs)\n",
    "single_coverage_df = ungrouped_single_coverage_df.groupby('max_state_error').agg({'prediction': 'sum', 'observed': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "plt.plot(coverage_df['max_state_error'], coverage_df['prediction'], label='MC Model Expects')\n",
    "plt.plot(single_coverage_df['max_state_error'], single_coverage_df['prediction'], label='Single Model Expects')\n",
    "plt.plot(single_coverage_df['max_state_error'], coverage_df['observed'], 'k--', label='Actual')\n",
    "\n",
    "ax.set_xlabel('Max Allowed Vote Error')\n",
    "ax.set_ylabel('Galaxies Within Max Error')\n",
    "ax.legend()\n",
    "ax.xaxis.set_major_formatter(StrMethodFormatter('{x:.0f}'))  # must expect 'x' kw arg\n",
    "\n",
    "ax.set_xlim([0, 15])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'coverage_comparison_200_samples.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'coverage_comparison_200_samples.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_ungrouped_coverage_df.csv'), index=False)\n",
    "ungrouped_single_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_ungrouped_coverage_df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df['error'] = coverage_df['prediction'] - coverage_df['observed']\n",
    "coverage_df['relative_error'] = coverage_df['error'] / coverage_df['observed']\n",
    "coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_coverage_df.csv'), index=False)\n",
    "coverage_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_coverage_df['error'] = single_coverage_df['prediction'] - single_coverage_df['observed']\n",
    "single_coverage_df['relative_error'] = single_coverage_df['error'] / single_coverage_df['observed']\n",
    "single_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_single_coverage_df.csv'), index=False)\n",
    "single_coverage_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - I might consider adding an MSE model as a comparison, to hopefully beat. I think this might be quite similar though. Ideally I can compare this with previous work somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(sim_model.abs_rho_error, bins=25)\n",
    "# ax.axvline(sim_model.mean_abs_rho_error, color='r') \n",
    "ax.set_xlim([0, 1.])\n",
    "ax.set_ylabel('Galaxies')\n",
    "ax.set_xlabel(r'| Expected $\\hat{\\rho}$ - observed vote fraction $\\frac{k}{N}$ |')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'difference_in_rho.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'difference_in_rho.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.abs_rho_error.mean(), single_sim_model.abs_rho_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sim_model.mean_abs_rho_error), np.sqrt(single_sim_model.mean_abs_rho_error)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sim_model.mean_square_rho_error), np.sqrt(single_sim_model.mean_square_rho_error) # this is the rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 0.3\n",
    "# n_bins = 25\n",
    "\n",
    "# # dummy for bins\n",
    "# fig, ax = plt.subplots()\n",
    "# _, bins, _  = ax.hist(sim_model.labels / sim_model.total_votes, bins=n_bins, alpha=alpha, label=r'Observed $\\rho$')\n",
    "# ax.hist(sim_model.mean_rho_prediction, bins=n_bins, alpha=alpha, label=r'Mean Rho Prediction $\\hat{\\rho}}$')\n",
    "# # ax.hist(single_sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Single Rho Prediction $\\hat{\\rho}}$')\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# sns.set(font_scale=1.)\n",
    "# sns.set_style('white')\n",
    "\n",
    "# ax.hist(sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Mean Rho Prediction $\\hat{\\rho}}$')\n",
    "# # ax.hist(single_sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Single Rho Prediction $\\hat{\\rho}}$')\n",
    "# ax.hist(sim_model.labels / sim_model.total_votes, bins=bins, alpha=alpha, label=r'Observed $\\rho$')\n",
    "# ax.legend()\n",
    "# ax.set_xlim([0., 1.])\n",
    "# ax.set_ylabel('Galaxies')\n",
    "# ax.set_xlabel(r'Typical vote fraction $\\rho$')\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(os.path.join(save_dir, 'typical_vote_fraction_distribution.png'))\n",
    "\n",
    "# This is a repeat of the above histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sim_model.mean_rho_prediction > 0.5), np.sum(single_sim_model.mean_rho_prediction > 0.5), np.sum((sim_model.labels / sim_model.total_votes) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sim_model.labels / sim_model.total_votes).min(), (sim_model.labels / sim_model.total_votes).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.mean_rho_prediction.min(), sim_model.mean_rho_prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sim_model.mean_rho_prediction.min(), single_sim_model.mean_rho_prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.total_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrame of predictions + catalog (GZ2) for use elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.DataFrame(data={\n",
    "    'total_votes': sim_model.total_votes, \n",
    "    'k': sim_model.labels, \n",
    "    'vote_fraction': (sim_model.labels / sim_model.total_votes), \n",
    "    'rho_prediction': sim_model.mean_rho_prediction\n",
    "#     'png_loc': sim_model.catalog.png_loc\n",
    "})\n",
    "safe_catalog_cols = list(set(sim_model.catalog.columns.values) - set(['total_votes', 'ra_subject', 'dec_subject']))\n",
    "df = pd.concat([response_df, sim_model.catalog[safe_catalog_cols]], axis=1)\n",
    "df['smooth'] = df['vote_fraction'] > 0.5\n",
    "df['confidence_proxy'] = np.abs(0.5 - df['rho_prediction'])\n",
    "df['rho_predictions'] = 0\n",
    "for n in range(len(df)):\n",
    "    df['rho_predictions'][n] = json.dumps(list(sim_model.model.samples[n, :]))\n",
    "    df = df.sort_values('confidence_proxy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rho_predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('/data/repos/zoobot/notebooks/{}_test_predictions_and_gz2_catalog.parquet'.format(QUESTION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate (ish) Sanchez 2017 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix((sim_model.labels / sim_model.total_votes) > 0.5, sim_model.mean_rho_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1 - ((66 + 99) / (490 + 1845 + 66 + 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1 - ((189 + 81) / (1858 + 189 + 81 + 372))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(df['smooth'], df['rho_prediction'])\n",
    "ax.plot(fpr, tpr, label='All')\n",
    "df_low_entropy = df[df['confidence_proxy'] > 0.3]\n",
    "fpr, tpr, _ = roc_curve(df_low_entropy['smooth'], df_low_entropy['rho_prediction'])\n",
    "ax.plot(fpr, tpr, label=r'\"High Confidence\" i.e. $\\hat{\\rho} < 0.2$ or $\\hat{\\rho} > 0.8$')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'roc_curve.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'roc_curve.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(df_low_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate(ish) Khan 2018 Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After selecting the OBJIDs from Table 2 based on the probability thresholds of 0.985 and 0.926 for spirals and ellipticals respectively,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_array = binom.cdf((df['total_votes'] / 2.).astype(int), df['total_votes'], df['rho_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['total_votes'] / 2.).astype(int).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_votes'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rho_prediction'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cdf_array, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.cdf(20, 40, 0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(1 - cdf_array > 0.985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cdf_array > 0.926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_df = df[(cdf_array < (1 - 0.985)) | (cdf_array > 0.926)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(high_prob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUESTION == 'smooth':\n",
    "    spiral_pc_to_keep = 516 / 6677\n",
    "    n_spirals = int(len(df) * spiral_pc_to_keep)\n",
    "    elliptical_pc_to_keep = 550 / 5904\n",
    "    n_ellipticals = int(len(df) * elliptical_pc_to_keep)\n",
    "    print(spiral_pc_to_keep, n_spirals, elliptical_pc_to_keep, n_ellipticals)\n",
    "    high_prob_df = pd.concat([\n",
    "        df.sort_values('rho_prediction')[:n_spirals],\n",
    "        df.sort_values('rho_prediction', ascending=False)[:n_ellipticals]\n",
    "    ])\n",
    "if QUESTION == 'bars':\n",
    "    n_to_keep = int(len(df) * 0.08)\n",
    "    high_prob_df = pd.concat([\n",
    "        df.sort_values('rho_prediction')[:int(n_to_keep/2)],\n",
    "        df.sort_values('rho_prediction', ascending=False)[:int(n_to_keep/2)]\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(high_prob_df['vote_fraction'] >= 0.5, high_prob_df['rho_prediction'] >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = high_prob_df[~(high_prob_df['vote_fraction'] > 0.5) & (high_prob_df['rho_prediction'] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error['vote_fraction'] > 0.5, error['rho_prediction'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(error.iloc[0]['png_loc'])\n",
    "plt.imshow(img)\n",
    "fontdict = {'size': 16, 'color': 'white'}\n",
    "plt.text(30, 360, r'Expected vote frac $\\hat{\\rho}$: 0.80', fontdict=fontdict)\n",
    "plt.text(30, 400, r'Observed vote frac $\\frac{k}{N}$: 0.50', fontdict=fontdict)\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(save_dir, 'high_prob_error_0.png'))\n",
    "plt.savefig(os.path.join(save_dir, 'high_prob_error_0.eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(error.iloc[1]['png_loc'])\n",
    "# plt.imshow(img)\n",
    "# fontdict = {'size': 16, 'color': 'white'}\n",
    "# plt.text(30, 360, r'Expected vote frac $\\hat{\\rho}$: 0.13', fontdict=fontdict)\n",
    "# plt.text(30, 400, r'Observed vote frac $\\frac{k}{N}$: 0.54', fontdict=fontdict)\n",
    "# plt.axis('off')\n",
    "# plt.savefig(os.path.join(save_dir, 'high_prob_error_1.png'))\n",
    "# plt.savefig(os.path.join(save_dir, 'high_prob_error_1.eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df['vote_fraction'][:int(len(df) / 2)] > 0.5, df['rho_prediction'][:int(len(df) / 2)] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUESTION == 'smooth':\n",
    "    labels = ['Smooth', 'Featured']\n",
    "    \n",
    "#     cm = np.array([[ 232,    2], [   0, 191]])\n",
    "#     name = 'confusion_matrix_high_confidence'\n",
    "    \n",
    "    cm = np.array([[ 490,   66],\n",
    "       [  99, 1845]])\n",
    "    name = 'confusion_matrix'\n",
    "    \n",
    "if QUESTION == 'bars':\n",
    "    labels = ['No Bar', 'Bar']\n",
    "    cm = np.array([[100,    0], [   0,   100]])\n",
    "    name = 'confusion_matrix_high_confidence'\n",
    "    \n",
    "#     cm = np.array([[1858,    81], [   189,   372]])\n",
    "#     name = 'confusion_matrix'\n",
    "\n",
    "sns.set(font_scale=3.)\n",
    "sns.set_style('white')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels, cbar=False, square=True, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Observed')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, '{}.png'.format(name)))\n",
    "fig.savefig(os.path.join(save_dir, '{}.pdf'.format(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (8 / (1159 + 83 + 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_model.export_performance_metrics(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a galaxy, infer a range of p, redraw, and measure accuracy - work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot other standard acquisition visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_acquisition_viz = False\n",
    "if new_acquisition_viz:\n",
    "    image_locs = sim_model.catalog['png_loc']\n",
    "    images = np.stack([np.array(Image.open(loc)) for loc in image_locs])\n",
    "    assert images.shape == (2500, 424, 424, 3)\n",
    "    acquisition_utils.save_acquisition_examples(images, sim_model.mutual_info, 'mutual_info', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, row = plt.subplots(ncols=3, figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = sim_model.acquisition_vs_volunteer_votes(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Selection of Catalog Features w.r.t. Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(20, 12))\n",
    "gs = gridspec.GridSpec(6, 5, figure=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smooth Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:4, :])\n",
    "sns.scatterplot(\n",
    "    np.array(sim_model.catalog['smooth-or-featured_smooth_fraction'] * 40).astype(int),\n",
    "    sim_model.model.acquisitions, hue=np.array(sim_model.model.acquisitions) > np.array(sim_model.model.acquisitions[103]),\n",
    "    ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel('Smooth Votes')\n",
    "ax0.legend([r'Top 10% $\\mathcal{I}$', r'Bottom 90% $\\mathcal{I}$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(gs[4:, :])\n",
    "ax1.hist(np.array(sim_model.labels * 40).astype(int), density=True, alpha=0.4)\n",
    "ax1.hist(np.array(sim_model.labels * 40).astype(int)[:200], density=True, alpha=0.4)\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlabel('Smooth Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(save_dir, 'temp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.jointplot(np.array(sim_model.labels * 40).astype(int), sim_model.catalog['redshift'], kind='kde')\n",
    "ax0.set_ylabel('Redshift')\n",
    "ax0.set_xlabel('Volunteer Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.jointplot(np.array(sim_model.labels * 40).astype(int), sim_model.catalog['redshift'], kind='kde', ax=ax0)\n",
    "ax0.set_ylabel('Redshift')\n",
    "ax0.set_xlabel('Volunteer Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.jointplot(sim_model.catalog['redshift'], sim_model.model.acquisitions, ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel('Redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(gs[4:, :])\n",
    "\n",
    "ax1.hist(sim_model.catalog['redshift'], density=True, alpha=0.4)\n",
    "# ax1.hist(sim_model.catalog['redshift'], density=True, alpha=0.4)\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlabel('Smooth Votes')\n",
    "# TODO sort by mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below here is only relevant for DECALS, with extra questions. TODO update with GZ2 merger options?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_label = 'merging_major-disturbance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.scatterplot(sim_model.catalog[merger_label], sim_model.model.mutual_info, ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel(merger_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(sim_model.catalog[merger_label], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_no_merger = sim_model.model.mutual_info[(sim_model.catalog[merger_label] == 0) & (sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.4)]\n",
    "featured_merger = sim_model.model.mutual_info[(sim_model.catalog[merger_label] > 0) & (sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_no_merger.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_merger.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(featured_no_merger, alpha=0.3, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(featured_merger, alpha=0.3, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'], \n",
    "    sim_model.model.mutual_info, \n",
    "    hue=sim_model.model.mutual_info > sim_model.model.mutual_info[103])\n",
    "ax.set_xlim([0, 14.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'], \n",
    "    sim_model.model.mutual_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has-spiral-arms_yes\n",
    "spiral-winding_prediction-encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.5], \n",
    "    sim_model.model.mutual_info[sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.5], \n",
    "    hue=sim_model.model.mutual_info > sim_model.model.mutual_info[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['redshift'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['redshift'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['merging_major-disturbance'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['merging_major-disturbance'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for merger_label in merger_strs:\n",
    "    print('\\n' + merger_label)\n",
    "    print(sim_model.model.mutual_info[sim_model.catalog[merger_label] > 1].mean())\n",
    "    print(sim_model.model.mutual_info[sim_model.catalog[merger_label] == 1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'Volunteer Response': 'Merging', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_both-v1'] > 1].mean()},\n",
    "    {'Volunteer Response': 'Major Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_major-disturbance'] > 1].mean()},\n",
    "    {'Volunteer Response': 'Minor Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_minor-disturbance'] > 1].mean()},\n",
    "    {'Volunteer Response': 'No Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_none'] > 20].mean()}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(data=df, y='Volunteer Response', x='Mean Mutual Information', ax=ax)\n",
    "ax.set_xlim([0.2, 0.36])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_model.model.mutual_info[(sim_model.catalog['merging_minor-disturbance'] + sim_model.catalog['merging_major-disturbance']) > 0].mean())\n",
    "print(sim_model.model.mutual_info[(sim_model.catalog['merging_minor-disturbance'] + sim_model.catalog['merging_major-disturbance']) == 0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_model.catalog['merging_tidal-debris-v1'], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('zoobot': conda)",
   "language": "python",
   "name": "python37664bitzoobotcondad3adbdfef5c444648572db3b6ec7c1e0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
